<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>Realtime Chat with WebRtc</title>
  <style>
    .button {
      padding: 10px 20px;
      margin: 10px;
      font-size: 16px;
      cursor: pointer;
    }

    .container {
      text-align: center;
      margin-top: 50px;
    }
  </style>
</head>

<body>
  <script>
    let audioContext;
    let mediaStream;
    let mediaStreamSource;
    let scriptProcessor;
    let isMuted = false;
    let recorderReady = false;
    let playerReady = false;
    let latestPlayTime = null;
    let sourceSequence = [];
    var dataChannel = null;

    console.log('Webview webrtc Realtime API: running websocket_realtime_page.html');

    async function start(wsUrl, model, apiKey, sampleRate, numChannels, sampleSize) {
      console.log('Webview webrtc Realtime API: start', wsUrl, model, apiKey, sampleRate, numChannels, sampleSize);
      const token = await _getEphemeralToken(wsUrl, model, apiKey);

      const pc = new RTCPeerConnection();
      const audioEl = document.createElement("audio");
      audioEl.autoplay = true;
      pc.ontrack = e => audioEl.srcObject = e.streams[0];
      const ms = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: sampleRate,
          channelCount: numChannels,
          sampleSize: sampleSize,
          echoCancellation: true,
        },
        video: false,
      });
      pc.addTrack(ms.getTracks()[0]);
      const dc = pc.createDataChannel("oai-events");
      dc.addEventListener("message", (e) => {
        console.log(e);
      });
      const offer = await pc.createOffer();
      const sdpResponse = await fetch(`${wsUrl}?model=${model}`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${token}`,
          "Content-Type": "application/sdp"
        },
      });
      const answer = {
        type: "answer",
        sdp: await sdpResponse.text(),
      };
      await pc.setRemoteDescription(answer);
    }

    async function _getEphemeralToken(url, model, apiKey) {
      try {
        const response = await fetch(url + '/sessions', {
          method: 'POST',
          headers: {
            'Authorization': 'Bearer ' + apiKey,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: model,
            voice: "alloy",
          }),
        });

        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        console.log('Webview webrtc Realtime API: get ephemeral token', data);
        const clientSecret = data.client_secret.value;
        if(clientSecret == null) {
          throw new Error('Webview webrtc Realtime API: get ephemeral token failed, client_secret is null');
        }
        return clientSecret;
      } catch (error) {
        console.error('Webview webrtc Realtime API: get ephemeral token failed', error);
        throw error;
      }
    }

    async function startRecording(sampleRate, numChannels, sampleSize) {
      console.log('Webview webrtc Realtime API: startRecording');
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: sampleRate,
          latencyHint: 'interactive'
        });
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: sampleRate,
            channelCount: numChannels,
            sampleSize: sampleSize,
            // noiseSuppression: true,
            echoCancellation: true,
            // autoGainControl: true
          } 
        });

        mediaStreamSource = audioContext.createMediaStreamSource(mediaStream);
        scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);

        mediaStreamSource.connect(scriptProcessor);
        scriptProcessor.connect(audioContext.destination);

        console.log('Webview webrtc Realtime API: AudioContext.state before resume', audioContext.state);
        audioContext.resume().then(() => {
          console.log('Webview webrtc Realtime API: AudioContext.state after resume', audioContext.state);
        });

        scriptProcessor.onaudioprocess = function (e) {
          if (!isMuted) {
            const inputData = e.inputBuffer.getChannelData(0);
            const uint8Data = new Uint8Array(inputData.length * 2);
            for (let i = 0; i < inputData.length; i++) {
              const sample = Math.round(inputData[i] * 0x7FFF);
              uint8Data[i * 2] = sample & 0xFF;
              uint8Data[i * 2 + 1] = (sample >> 8) & 0xFF;
            }
            const base64Data = btoa(String.fromCharCode.apply(null, uint8Data));
            _appendInputAudio(base64Data);
          }
        };
      } catch (err) {
        console.log('Webview webrtc Realtime API: Error accessing microphone:', err);
      }
      recorderReady = true;
      tryToReportAudioReady();
    }

    function playAudio(data, itemId, contentIndex, volume = 1.0) {
      // console.log('Webview webrtc Realtime API: playAudio', data, itemId, contentIndex);
      if(audioContext == null) {
        console.warn('Webview webrtc Realtime API: audioContext is null');
        return;
      }
      const binaryString = atob(data);
      const uint8Data = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        uint8Data[i] = binaryString.charCodeAt(i);
      }
      
      // Convert Uint8Array to Int16Array
      const int16Data = new Int16Array(uint8Data.buffer);
      
      // Convert Int16Array to Float32Array (normalize to -1 to 1)
      const float32Data = new Float32Array(int16Data.length);
      for (let i = 0; i < int16Data.length; i++) {
        // Divide by 0x7FFF (32767) to normalize
        float32Data[i] = int16Data[i] / 0x7FFF * volume;
      }

      const audioBufferObj = audioContext.createBuffer(1, float32Data.length, audioContext.sampleRate)
      audioBufferObj.copyToChannel(float32Data, 0) // Copy PCM data to the buffer

      // Create a BufferSource to play the audio
      const source = audioContext.createBufferSource()
      source.buffer = audioBufferObj
      source.connect(audioContext.destination)

      // If playing queue is empty, update latestPlayTime to current time
      if(sourceSequence.length <= 0 || latestPlayTime == null) {
        latestPlayTime = audioContext.currentTime;
      }
      let startTime = latestPlayTime;
      const duration = float32Data.length / audioContext.sampleRate
      const endTime = startTime + duration;

      source.onended = () => {
        // console.log('source.onended');
        sourceSequence.shift();
        if(sourceSequence.length > 0) {
          let first = sourceSequence[0];
          updatePlayingBufferInfo(first.itemId, first.contentIndex, first.startTime * 1000);
        } else {
          playEnded();
        }
      }

      latestPlayTime = endTime;
      source.start(startTime, 0, duration)

      sourceSequence.push({
        source,
        startTime,
        endTime,
        itemId,
        contentIndex,
      })
    }

    function startPlayer() {
      console.log('Webview webrtc Realtime API: startPlayer');
    }

    function stopRecording() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream.getAudioTracks().forEach(track => track.stop());
      }
      if (scriptProcessor) {
        scriptProcessor.disconnect();
      }
      if (mediaStreamSource) {
        mediaStreamSource.disconnect();
      }
      if (audioContext) {
        audioContext.close();
      }
    }

    function clearPlayingBuffers() {
      for(let i = 0; i < sourceSequence.length; i++) {
        let source = sourceSequence[i].source;
        source.stop();
        source.disconnect();
      }
      sourceSequence = [];
    }

    function sendBase64Event(base64Data) {
      _sendEvent(atob(base64Data));
    }

    function mute() {
      console.log('Webview webrtc Realtime API: mute');
      isMuted = true;
    }

    function unmute() {
      console.log('Webview webrtc Realtime API: unmute');
      isMuted = false;
    }

    function shutdownAll() {
      console.log('Webview webrtc Realtime API: shutdownAll');
      stopRecording();
      clearPlayingBuffers();
      window.webSocket.close();
    }

    function _sendEvent(data) {
      window.webSocket.send(data);
    }
    function _sendJsonEvent(data) {
      _sendEvent(JSON.stringify(data));
    }
    function _appendInputAudio(base64Data) {
      // MyLogger.info('Native WebSocket Realtime API append input audio: $base64Data');
      const appendInputAudioObject = {
        'type': 'input_audio_buffer.append',
        'audio': base64Data,
      };
      _sendJsonEvent(appendInputAudioObject);
    }
    function _onInterrupt() {
      console.log('Webview webrtc Realtime API: onInterrupt');
      clearPlayingBuffers();
      // truncateInfo = audioPlayerProxy.stop();
      const truncateInfo = getTruncateInfo();
      if(truncateInfo != null) {
        console.log('Webview webrtc Realtime API: Interrupt, truncate info: ', truncateInfo.itemId, truncateInfo.contentIndex, truncateInfo.audioEndMs);
        _truncate(truncateInfo);
      } else {
        console.log('Webview webrtc Realtime API: no truncate info');
      }
    }
    function _truncate(truncateInfo) {
      const truncateObject = {
        'type': 'conversation.item.truncate',
        'item_id': truncateInfo.itemId,
        'content_index': truncateInfo.contentIndex,
        'audio_end_ms': truncateInfo.audioEndMs,
      };
      _sendJsonEvent(truncateObject);
    }

    class TruncateInfo {
      constructor(itemId, contentIndex, audioEndMs) {
        this.itemId = itemId;
        this.contentIndex = contentIndex;
        this.audioEndMs = audioEndMs;
      }
    }
    class _PlayingBufferInfo {
      constructor(itemId, contentIndex, startTimeMs) {
        this.itemId = itemId;
        this.contentIndex = contentIndex;
        this.startTimeMs = startTimeMs;
      }
    }
    var _currentPlayingBufferInfo = null;
    var _startTimeMsAtTheBeginning = null;

    function updatePlayingBufferInfo(itemId, contentIndex, startTimeMs) {
      let oldItemId = _currentPlayingBufferInfo?.itemId;
      if(oldItemId != itemId || _startTimeMsAtTheBeginning == null) {
        _startTimeMsAtTheBeginning = startTimeMs;
      }
      _currentPlayingBufferInfo = _PlayingBufferInfo(itemId, contentIndex, startTimeMs);
    }
    function playEnded() {
      _currentPlayingBufferInfo = null;
      _startTimeMsAtTheBeginning = null;
    }
    function getTruncateInfo() {
      if(_currentPlayingBufferInfo == null || _startTimeMsAtTheBeginning == null) {
        return null;
      }
      const result = TruncateInfo(
        _currentPlayingBufferInfo.itemId,
        _currentPlayingBufferInfo.contentIndex,
        _currentPlayingBufferInfo.startTimeMs - _startTimeMsAtTheBeginning,
      );
      playEnded();
      return result;
    }
  </script>
</body>

</html>